{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f005636-ecfe-4cc3-afa1-e717b16661d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "488it [00:12, 38.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# This is code takes input as your interested STR regions and SNP loci and check if any read in the a perticular STR region is enclosing the read and the same time the Snp loci (matching the snp allele with the reference or alternative allele) finally it gives the variation occured in STR region which is associating with the Snp allele.\n",
    "\n",
    "# packages\n",
    "\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import pysam\n",
    "import sys\n",
    "\n",
    "\n",
    "# Below block is the main function which calls the other functions like (snp_allele_origin_classification(), snp_check(), STR_variation_from_read(), Snp_AssociatedSTR_GT())\n",
    "\n",
    "# Dictionary which contains Trio id's and it's relavent Off-spring id's\n",
    "# list_of_files = '../../Analysis_AV/1KG_Trio_Samples.tsv'\n",
    "# files_information = {}\n",
    "\n",
    "# with open(f'{list_of_files}') as file_info:\n",
    "#     file_info.readline()\n",
    "\n",
    "#     for Trio_id in file_info:\n",
    "#         Trio_id = Trio_id.strip().split('\\t')\n",
    "#         files_information[Trio_id[0]]= Trio_id[2]\n",
    "\n",
    "\n",
    "        \n",
    "# Calling the argument using os.sys[]\n",
    "# Trio_id = sys.argv[1]\n",
    "\n",
    "\n",
    "# Read and Write directory.\n",
    "Read_directory = '../../data_pysam/cram/'\n",
    "Write_directory = '../../data_pysam/cram/'\n",
    "Pysam_Read_directory = '../../data_pysam/cram/'\n",
    "\n",
    "def Trio_file_id(Trio_id):\n",
    "    \n",
    "    single_file_id = Trio_id\n",
    "    # pysam_infile = files_information[Trio_id1]\n",
    "    with open(f'{Read_directory}{single_file_id}_HM_intermediate.tsv') as Trio_file:\n",
    "\n",
    "        out = open(f'{Write_directory}{single_file_id}_HM_Phased_mDNMs.tsv', 'w')\n",
    "\n",
    "        samfile = pysam.AlignmentFile(f'{Pysam_Read_directory}{single_file_id}.final.cram', \"rc\")\n",
    "\n",
    "        for repeat_region in tqdm(Trio_file):\n",
    "\n",
    "            repeat_region = repeat_region.strip().split('\\t')\n",
    "            #\n",
    "            start =  int(repeat_region[1])  \n",
    "            end =    int(repeat_region[2])\n",
    "            chrom = repeat_region[0]\n",
    "\n",
    "            snp_pos = int(repeat_region[-5]) - 1\n",
    "            snp_gts = [repeat_region[-4], repeat_region[-3]]\n",
    "            snp_gts_representation = [repeat_region[-8], repeat_region[-7], repeat_region[-6]]\n",
    "            denovo_gts = repeat_region[5].split('|') # change the var name : denovo_gts to offspring alleles\n",
    "            repeat_len = end - start\n",
    "\n",
    "            # here we are calling the function to store the snp allele parent of origin.\n",
    "            snp_allele_origin = snp_allele_origin_classification(snp_gts, snp_gts_representation)\n",
    "\n",
    "            # dictionary to maintian the snp_loc and repeat region enclosing the reads.\n",
    "            read_info = {}\n",
    "\n",
    "            #\n",
    "            Read_depth_5percent = 0    \n",
    "            for read_depth,read in enumerate(samfile.fetch(chrom,start, end)):\n",
    "\n",
    "                # read quality >= 1.\n",
    "                if read.mapping_quality >= 1: #******* changed the read mapping quality.\n",
    "                    Read_depth_5percent += 1\n",
    "\n",
    "                    Read = ''\n",
    "                    if read.is_read1: Read = 'R1'\n",
    "                    else: Read = 'R2'\n",
    "\n",
    "                    read_query = read.query_name\n",
    "                    read_start = read.reference_start\n",
    "                    read_end = read.reference_end\n",
    "                    base_info = sum(read.get_aligned_pairs(with_seq=True), ())\n",
    "\n",
    "                    # checking if the ( read is enclosed) and ( covering the interested snp position in the flank). { R1:[s,e],[reference pos],[read base at reference pos] }\n",
    "                    if not read_query in read_info: \n",
    "                        read_info[read_query] = {'R1':[], 'R2':[], 'Allele_on':[]}\n",
    "\n",
    "                        #\n",
    "                        snp_on_read_info = snp_check(read, snp_pos, Read, snp_gts, base_info)            \n",
    "                        Read_lenvar_info = STR_variation_from_read(read, start, end, repeat_len)\n",
    "                        read_info[read_query]['Allele_on'].extend(snp_on_read_info)\n",
    "                        read_info[read_query][Read].append(Read_lenvar_info)\n",
    "                        # print(snp_on_read_info)\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        snp_on_read_info = snp_check(read, snp_pos, Read, snp_gts, base_info)            \n",
    "                        Read_lenvar_info = STR_variation_from_read(read, start, end, repeat_len)\n",
    "                        read_info[read_query]['Allele_on'].extend(snp_on_read_info)\n",
    "                        read_info[read_query][Read].append(Read_lenvar_info)\n",
    "                        # print(snp_on_read_info)\n",
    "\n",
    "            # Calling the function which gives Snps associated with STR alleles.\n",
    "            Snp_AssociatedSTR_GT_print = Snp_AssociatedSTR_GT(read_info, snp_gts,denovo_gts)\n",
    "\n",
    "            # printing the required data.\n",
    "            if len(Snp_AssociatedSTR_GT_print) > 0:\n",
    "                print(*repeat_region[:5],repeat_region[5],repeat_region[6],repeat_region[7],repeat_region[8],f'{snp_gts[0]}|{snp_gts[1]}',f'{snp_allele_origin[0]}:{snp_allele_origin[1]};{snp_allele_origin[2]}:{snp_allele_origin[3]}', Snp_AssociatedSTR_GT_print,Read_depth_5percent, read_depth+1,repeat_region[-1], repeat_region[-2], file=out, sep = '\\t')\n",
    "\n",
    "\n",
    "        samfile.close()\n",
    "\n",
    "        out.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# **** Function 1: Snp_AssociatedSTR_GT()\n",
    "# ****************************************************************************************************************************************************************************************\n",
    "# Function which returns the Denovo genotype assiciating with the Snp genotype bases which further can be related to Denovo allele parent of origin.\n",
    "\n",
    "def Snp_AssociatedSTR_GT(read_info, snp_gts, denovo_gts):\n",
    "    \n",
    "    # A copy of read_info dictionary to delete the read id's which are not usefull. ()\n",
    "    read_info_copy = read_info.copy()\n",
    "    Dnv_PofO = []    \n",
    "    \n",
    "    # Before entering into the current repeat region read_info dictionary, we must ignore if ( read is not enclosed the repeat region | No snp on any read | or snp on R1 or R2 but no read overlapping the repeat region.\n",
    "    for read_id in read_info:\n",
    "        \n",
    "        if len(read_info[read_id]['Allele_on']) < 2 or len(read_info[read_id]['R1'])==0 and len(read_info[read_id]['R2'])==0 : read_info_copy.pop(read_id)\n",
    "        elif len(read_info[read_id]['R1']) == 1 and read_info[read_id]['R1'][0] == 0  and  len(read_info[read_id]['R2']) == 1 and read_info[read_id]['R2'][0] == 0 : read_info_copy.pop(read_id)\n",
    "        elif read_info[read_id]['Allele_on'].count(0) > 1: read_info_copy.pop(read_id)\n",
    "    \n",
    "    # Snp_alleles_to_DnvAllele_counts dict gets updated with SNP alleles and STR lens coming from those reads.\n",
    "    Snp_alleles_to_DnvAllele_counts = {snp_gts[0]:[], snp_gts[1]:[]} \n",
    "    \n",
    "    # Updating the Snp_alleles_to_DnvAllele_counts dict with STR allele lens.\n",
    "    list_DnvAlleles = [Snp_alleles_to_DnvAllele_counts[read_info_copy[read_ID]['Allele_on'][1].upper()].extend(read_info_copy[read_ID]['R1'] + read_info_copy[read_ID]['R2']) for read_ID in read_info_copy.keys() if read_info_copy[read_ID]['Allele_on'][0] != 0]\n",
    "    list_DnvAlleles1 = [Snp_alleles_to_DnvAllele_counts[read_info_copy[read_ID]['Allele_on'][2].upper()].extend(read_info_copy[read_ID]['R1'] + read_info_copy[read_ID]['R2']) for read_ID in read_info_copy.keys() if read_info_copy[read_ID]['Allele_on'][0] == 0]\n",
    "    \n",
    " \n",
    "    # In here we are considering the major count allele associating with Snp allele.\n",
    "    for i,snp_allele in enumerate(Snp_alleles_to_DnvAllele_counts.keys()):\n",
    "        \n",
    "        # In here we are doing Counter\n",
    "        snp_allele_itr = Counter(Snp_alleles_to_DnvAllele_counts[snp_allele])\n",
    "        if len(snp_allele_itr) == 0 : continue\n",
    "        \n",
    "        #\n",
    "        if int(denovo_gts[0]) in snp_allele_itr or int(denovo_gts[1]) in snp_allele_itr:\n",
    "            \n",
    "            # Deleting the 0's from the list of alleles, where 0 means that perticular read is not enclosing the repeat region.\n",
    "            if 0 in snp_allele_itr: snp_allele_itr.pop(0) \n",
    "            \n",
    "            #\n",
    "            if len(list(snp_allele_itr)) == 0: continue\n",
    "            \n",
    "            values = list(snp_allele_itr.values())\n",
    "            keys = list(snp_allele_itr.keys())\n",
    "\n",
    "            #\n",
    "            index_max_value = values.index(max(values))            \n",
    "            Dnv_AlleleAssociated_snp = keys[index_max_value]\n",
    "            \n",
    "            #\n",
    "            if Dnv_AlleleAssociated_snp != 0:\n",
    "                Dnv_allele_depth = max(values)\n",
    "                Dnv_PofO.append([Dnv_AlleleAssociated_snp,snp_allele,Dnv_allele_depth])# Here we want to print not just the max read supporting allele, we print list of allele which are getting printed.\n",
    "        \n",
    "        \n",
    "    \n",
    "    return Dnv_PofO\n",
    "\n",
    "\n",
    "\n",
    "# Function2 : snp_check()\n",
    "# ****************************************************************************************************************************************************************************************\n",
    "# Creating function to check the snp_pos overlapping with which read and matching with which snp_allele\n",
    "\n",
    "def snp_check(read, snp_pos, Read, snp_gts, base_info):\n",
    "    \n",
    "    # base info = [read_pos, refn_pos, read_base]\n",
    "    reference_pos = list(base_info)[1::3]\n",
    "    read_bases = list(base_info)[2::3]\n",
    "    \n",
    "    # check if read is overalpped with snp_pos and base.\n",
    "    if snp_pos in reference_pos: # with the only confirmation that read.get_aligned_pairs() gives information like 'read_pos, reference_pos, base' for matched, deletion and substitution bases for other bases it reports None.\n",
    "        read_index = list(base_info).index(snp_pos)\n",
    "        # Here we are ignoring the deletion in snp_pos, coz as we are only considering substitutions from the snp_vcf file.\n",
    "        if base_info[read_index-1] != None: \n",
    "            read_base = list(str(read.query_sequence))[base_info[read_index-1]]\n",
    "\n",
    "            # checking if snp_pos base matchs with read base in same pos.\n",
    "            if read_base.upper() in snp_gts:\n",
    "                 return [Read, read_base]\n",
    "        \n",
    "            else: return []\n",
    "        \n",
    "        else: return []\n",
    "        \n",
    "    else: return []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function 3 : STR_variation_from_read()\n",
    "# ****************************************************************************************************************************************************************************************\n",
    "# Considering only Repeat overlapped CIGAR variants.\n",
    "\n",
    "def STR_variation_from_read(read, start, end, repeat_len):\n",
    "\n",
    "    \n",
    "    # 1st we check if the read is enclosing the repeat or not, if not then return the empty list.\n",
    "    if read.reference_start <= int(start)  and  read.reference_end >= int(end):\n",
    "        \n",
    "        # Finding out the way to get the CIGAR string pos in read, reference & type of variation.\n",
    "        # Then figuring out the way to include the way to fecth the info in our set of reads.\n",
    "\n",
    "        repeat_start = int(start)\n",
    "        repeat_end = int(end)\n",
    "\n",
    "\n",
    "        cigar_s = read.cigarstring\n",
    "        cigar_t = sum(read.cigartuples, ())\n",
    "\n",
    "        num_bases = list(cigar_t)[1::2]\n",
    "        alignment_type = list(cigar_t)[::2]\n",
    "\n",
    "        # We update while itterating through the read positions to cover the entire read positions with any len and capture the variations which encounter within the repeat region.\n",
    "        current_ref_pos = read.reference_start\n",
    "\n",
    "        # saving Insertions and deletions counts which are part of repeat region in the list.\n",
    "        change_in_len_insert = {'1':0}\n",
    "        change_in_len_del = []\n",
    "\n",
    "        for indx in range(len(alignment_type)): # this loop runs for every read, itterating through M's I's D's.\n",
    "\n",
    "            # Here we get the actual reference pos by substracting the reference pos with hard or soft clip bases.\n",
    "            if alignment_type[indx] == 1:\n",
    "                # adding the insertion counts to the dictionary change_in_len\n",
    "                if current_ref_pos in range(repeat_start-1, repeat_end+1) :\n",
    "                    change_in_len_insert['1'] += num_bases[indx]\n",
    "\n",
    "\n",
    "            elif alignment_type[indx] == 2:\n",
    "                # adding the deletion counts to the dict.\n",
    "                del_end_pos = (current_ref_pos + num_bases[indx])\n",
    "                l = [(change_in_len_del.append(1)) for del_pos in range(current_ref_pos+1, del_end_pos+1) if del_pos in range(repeat_start, repeat_end+1)] \n",
    "                current_ref_pos += num_bases[indx]\n",
    "\n",
    "\n",
    "            elif alignment_type[indx] not in [4,5]:\n",
    "                current_ref_pos += num_bases[indx]\n",
    "\n",
    "\n",
    "        # change in the len of read overlapping the repeat.\n",
    "        Insertion_substract_Deletion = int(change_in_len_insert['1']) - sum(change_in_len_del)\n",
    "        len_diff_in_read = repeat_len + Insertion_substract_Deletion\n",
    "\n",
    "\n",
    "        return len_diff_in_read\n",
    "\n",
    "\n",
    "    else: return 0\n",
    "\n",
    "\n",
    "\n",
    "# Function 4 : snp_allele_origin_classification()\n",
    "# ****************************************************************************************************************************************************************************************\n",
    "# Here we relate snp alleles to the maternal and paternal side.\n",
    "\n",
    "def snp_allele_origin_classification(snp_gts, snp_gts_representation):\n",
    "    \n",
    "    Snp_origin = []\n",
    "    \n",
    "    # We have to 0 or 1 being unique in list of GT combinations.\n",
    "    offspring = snp_gts_representation[0].split('|')\n",
    "    parents = snp_gts_representation[1].split('|') + snp_gts_representation[2].split('|')\n",
    "    GT_bases = {'0':snp_gts[0], '1':snp_gts[1]}\n",
    "    \n",
    "    # Based on the '0' and '1' counts, either being count 1 where that allele indicates it is coming from criteria satisfied condition.\n",
    "    p1 =  parents.count(offspring[0])\n",
    "    p2 = parents.count(offspring[1])\n",
    "    \n",
    "    #\n",
    "    paternal = snp_gts_representation[1]#.split('|')\n",
    "    maternal = snp_gts_representation[2]#.split('|')\n",
    "\n",
    "    # To findout the 0 or 1 coming from which parent.\n",
    "    if p1 == 1 and paternal.count(offspring[0]) == 1:\n",
    "        Snp_origin.extend([GT_bases[offspring[0]], 'P', GT_bases[offspring[1]], 'M'])\n",
    "    \n",
    "    elif p1 == 1 and maternal.count(offspring[0]) == 1:\n",
    "        Snp_origin.extend([GT_bases[offspring[0]], 'M', GT_bases[offspring[1]], 'P'])\n",
    "\n",
    "    elif paternal.count(offspring[1]) == 1:\n",
    "        Snp_origin.extend([GT_bases[offspring[1]], 'P', GT_bases[offspring[0]], 'M'])\n",
    "\n",
    "    else:  Snp_origin.extend([GT_bases[offspring[1]], 'M', GT_bases[offspring[0]], 'P'])\n",
    "\n",
    "\n",
    "    return Snp_origin\n",
    "\n",
    "\n",
    "\n",
    "# Passsing the Trio file name as an argument to the main function.\n",
    "Trio_file_id('HG03540')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42d8fd4c-1f32-48f9-9be0-4ab1a2a0747c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                  | 0/5 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not determine alignment length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m tqdm(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../Analysis_KT/SNP_Denovo/SNPs_Intermediate_Files/SNPs_AssociatedRepeats/\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_Test.tsv.gz\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m         \u001b[43mTrio_file_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 91\u001b[0m, in \u001b[0;36mTrio_file_id\u001b[0;34m(Trio_id)\u001b[0m\n\u001b[1;32m     89\u001b[0m read_start \u001b[38;5;241m=\u001b[39m read\u001b[38;5;241m.\u001b[39mreference_start\n\u001b[1;32m     90\u001b[0m read_end \u001b[38;5;241m=\u001b[39m read\u001b[38;5;241m.\u001b[39mreference_end\n\u001b[0;32m---> 91\u001b[0m base_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_aligned_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwith_seq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m, ())\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# checking if the ( read is enclosed) and ( covering the interested snp position in the flank). { R1:[s,e],[reference pos],[read base at reference pos] }\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m read_query \u001b[38;5;129;01min\u001b[39;00m read_info: \n",
      "File \u001b[0;32mpysam/libcalignedsegment.pyx:2015\u001b[0m, in \u001b[0;36mpysam.libcalignedsegment.AlignedSegment.get_aligned_pairs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpysam/libcalignedsegment.pyx:861\u001b[0m, in \u001b[0;36mpysam.libcalignedsegment.build_reference_sequence\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpysam/libcalignedsegment.pyx:746\u001b[0m, in \u001b[0;36mpysam.libcalignedsegment.build_alignment_sequence\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not determine alignment length"
     ]
    }
   ],
   "source": [
    "for file in tqdm(os.listdir('../../Analysis_KT/SNP_Denovo/SNPs_Intermediate_Files/SNPs_AssociatedRepeats/')):\n",
    "    \n",
    "    if file.endswith('_Test.tsv.gz'):\n",
    "        Trio_file_id(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bd5852-1bc2-4d97-9568-e21add23b6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
